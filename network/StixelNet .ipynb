{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on: http://www.bmva.org/bmvc/2015/papers/paper109/paper109.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import clear_output\n",
    "plt.rcParams['figure.figsize'] = [50, 10]\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flow_from_dataframe import flow_from_dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KITTI_IMAGE_WIDTH = 1242\n",
    "STIXEL_WIDTH = 24\n",
    "IMAGE_SIZE = (370,STIXEL_WIDTH)\n",
    "maximum_offset = KITTI_IMAGE_WIDTH//STIXEL_WIDTH \n",
    "BATCH_SIZE = 1000\n",
    "NUMBER_OF_BINS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_train/labels_no.csv')\n",
    "# bin labels\n",
    "bins = np.linspace(0, 370, NUMBER_OF_BINS)\n",
    "binned_values = []\n",
    "for index, row in df.iterrows():\n",
    "    binned_values.append(np.argmax(np.histogram(row['y'],bins)[0]))\n",
    "df['binned_y'] = pd.Series(binned_values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, train_df = np.split(df, [int(len(df)*0.2)], axis=0)\n",
    "\n",
    "core_idg = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    rescale=1.0/255.0)\n",
    "\n",
    "train_generator = flow_from_dataframe(\n",
    "    core_idg,train_df,\n",
    "    'img_path',\n",
    "    'binned_y',\n",
    "    'data_train/',\n",
    "    NUMBER_OF_BINS,\n",
    "    target_size = IMAGE_SIZE, \n",
    "    batch_size = BATCH_SIZE)\n",
    "test_generator = flow_from_dataframe(\n",
    "    core_idg,test_df,\n",
    "    'img_path',\n",
    "    'binned_y',\n",
    "    'data_train/',\n",
    "    NUMBER_OF_BINS,\n",
    "    target_size = IMAGE_SIZE, \n",
    "    batch_size = BATCH_SIZE)\n",
    "#print('%d overlapping images.'%list(set(list(test_generator._filepaths)).intersection(list(train_generator._filepaths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "i=0\n",
    "for t in train_generator:\n",
    "    plt.imshow(t[0][0])\n",
    "    print(t[1][0])\n",
    "    for j in range(len(t[1][0])):\n",
    "        if t[1][0][j] == 1:\n",
    "            plt.axhline(y=bins[j],color='red')\n",
    "            plt.axhline(y=bins[j+1],color='red')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "# Ground truth needs to be in that form: [ACTUAL_VALUE,BIN_OF_ACTUAL_VALUE, (NUMBER_OF_BINS-2)*Zero (zero padding)]\n",
    "# This is due to keras demanding dim(y_true) == dim(y_pred) But in this case this is not wanted.\n",
    "# Current notebook DOES NOT generate y_true in that manner, since this loss function is not working (for now).\n",
    "\n",
    "def P(y,y_pred,i):\n",
    "    i_1 = i+1\n",
    "    a_i = K.cast(K.gather(y_pred,i),'float32')\n",
    "    a_i_1 = K.cast(K.gather(y_pred,i_1),'float32')\n",
    "    c_i = K.cast(K.gather(bins,i),'float32')\n",
    "    c_i_1 = K.cast(K.gather(bins,i_1),'float32')\n",
    "    denominator = c_i_1 - c_i\n",
    "    first_half = a_i * (((c_i_1 - y) / denominator))\n",
    "    second_half = a_i_1 * ((y - c_i) / denominator)\n",
    "    return  first_half + second_half\n",
    "\n",
    "def pl_loss(y_true,y_pred):\n",
    "    y_true = K.cast(K.gather(y_true,0),'float32')\n",
    "    y_pred = K.cast(K.flatten(y_pred),\"float32\")\n",
    "    i = K.cast(K.gather(K.flatten(y_true),1),'int32')\n",
    "    return P(y_true,y_pred,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D,MaxPooling2D,Dense,Dropout,Flatten\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def StixelNet(loss='mean_squared_error',metrics=['accuracy'],number_of_bins=50):\n",
    "    inputs = Input((IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "    conv1 = Conv2D(64, (5,11), activation='relu',padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(4, 8))(conv1)\n",
    "    conv2 = Conv2D(200, (3,5), activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(4, 3))(conv2)\n",
    "    flattened = Flatten()(pool2)\n",
    "    dense1 = Dense(1024, kernel_initializer='he_normal', activation='relu')(flattened)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(2048, kernel_initializer='he_normal', activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.5)(dense2)\n",
    "    dense3 = Dense(number_of_bins, kernel_initializer='he_normal', activation='softmax')(dropout2)\n",
    "    model = Model(inputs=inputs, outputs=dense3)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = StixelNet(loss=pl_loss,number_of_bins=NUMBER_OF_BINS,metrics=['accuracy',tf.keras.metrics.TopKCategoricalAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "steps_per_epoch = train_generator.n // BATCH_SIZE\n",
    "test_steps = test_generator.n // BATCH_SIZE\n",
    "\n",
    "#model.load_weights('best_model.hdf5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_model.hdf5\", \n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True, \n",
    "    mode='min', \n",
    "    period=1, \n",
    "    save_weights_only=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=400,\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=test_steps,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preds_to_class_pred(preds):\n",
    "    preds_class = []\n",
    "    for i in range(len(preds)):\n",
    "        preds_class.append(np.argmax(preds[i]))\n",
    "    return preds_class\n",
    "\n",
    "i = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for t in test_generator:\n",
    "    y_pred+=preds_to_class_pred(model.predict(t[0]))\n",
    "    y_true+=preds_to_class_pred(t[1])\n",
    "    if i>200:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true,y_pred)\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_true,y_pred), range(len(conf_matrix[0])), range(len(conf_matrix)))\n",
    "plt.figure(figsize=(50,50))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "class ImgFrame:\n",
    "    \n",
    "    def __init__(self,imagePath):\n",
    "        self.imagePath = imagePath\n",
    "        self.image = Image.open(self.imagePath)\n",
    "        self.image = self.image.resize((self.image.size[0],370))\n",
    "        \n",
    "    def getImage(self):\n",
    "        return np.array(Image.open(self.imagePath))\n",
    "\n",
    "    def getImageStixel(self,offset,stixelWidth):\n",
    "        width = self.image.size[0]\n",
    "        cropFromLeft = offset*stixelWidth \n",
    "        cropFromRight = width-(offset*stixelWidth)-stixelWidth\n",
    "        if cropFromRight < 0:\n",
    "            print('Offset too big for image.')\n",
    "            return (None,-1)\n",
    "        # left, up, right, bottom\n",
    "        border = (cropFromLeft,0,cropFromRight, 0)\n",
    "        return ImageOps.crop(self.image, border)\n",
    "    \n",
    "    def getImageStixels(self,stixelWidth):\n",
    "        stixels = []\n",
    "        for i in range(24):\n",
    "            stixels.append(np.array(self.getImageStixel(i,stixelWidth)) / 255.)\n",
    "        return np.array(stixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('training_wo_flips/best_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
